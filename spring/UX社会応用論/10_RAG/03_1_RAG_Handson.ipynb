{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJQ9LY48q5a5"
      },
      "source": [
        "# 1.LLMã‚’å°å…¥ã—ã¦ã¿ã‚ˆã†"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InNPx_oGGkQt"
      },
      "source": [
        "## 1.1.å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9PcGueRndzJ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-openai gradio python-dotenv langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMMeugUpGpTl"
      },
      "source": [
        "## 1.2.ChatGPTã®APIã‚­ãƒ¼ã®ç™»éŒ²"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7hj9IPQnor-"
      },
      "outputs": [],
      "source": [
        "# APIã‚­ãƒ¼ã®ç™»éŒ²\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'yyHDWJTRyxJBtgsEIE3Y7_BLZOHs5XDCVr0LfZQrzoOJ8cjsFqoy4-lYb5orGEwrH3OrwDEDq2wDc3TEJauWCHA'\n",
        "\n",
        "# openai_api_base=\"https://api.openai.com/v1/\"\n",
        "openai_api_base=\"https://api.openai.iniad.org/api/v1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OREs7gMFGtS9"
      },
      "source": [
        "## 1.3.Chatbotã®èµ·å‹•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1hkmegznYwl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.schema import HumanMessage, AIMessage\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
        "MODEL_NAME = \"gpt-4o-mini\"\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "class OpenAIChatbot:\n",
        "    def __init__(self):\n",
        "        # APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—\n",
        "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "        if not api_key:\n",
        "            raise ValueError(\"OPENAI_API_KEYãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\")\n",
        "\n",
        "        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦å®£è¨€ã•ã‚ŒãŸ openai_api_base ã‚’ä½¿ç”¨\n",
        "        global openai_api_base\n",
        "        print(f\"âœ… OpenAI Base URL: {openai_api_base}\")\n",
        "\n",
        "        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=MODEL_NAME,\n",
        "            temperature=TEMPERATURE,\n",
        "            base_url=openai_api_base,\n",
        "            openai_api_key=api_key,\n",
        "            streaming=False\n",
        "        )\n",
        "\n",
        "        self.memory = ConversationBufferWindowMemory(\n",
        "            k=10,\n",
        "            return_messages=True\n",
        "        )\n",
        "\n",
        "        self.system_prompt = \"\"\"ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n",
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã§æœ‰ç”¨ãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚\n",
        "ã‚ã‹ã‚‰ãªã„ã“ã¨ãŒã‚ã‚Œã°ã€ç´ ç›´ã«ã€Œã‚ã‹ã‚‰ãªã„ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚\n",
        "æ—¥æœ¬èªã§è‡ªç„¶ãªä¼šè©±ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚\"\"\"\n",
        "\n",
        "    def chat(self, user_input):\n",
        "      messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
        "      for msg in self.memory.chat_memory.messages:\n",
        "          if isinstance(msg, HumanMessage):\n",
        "              messages.append({\"role\": \"user\", \"content\": msg.content})\n",
        "          elif isinstance(msg, AIMessage):\n",
        "              messages.append({\"role\": \"assistant\", \"content\": msg.content})\n",
        "      messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "      try:\n",
        "          with get_openai_callback() as cb:\n",
        "              response = self.llm.invoke(messages)\n",
        "          self.memory.chat_memory.add_user_message(user_input)\n",
        "          self.memory.chat_memory.add_ai_message(response.content)\n",
        "          return response.content\n",
        "      except Exception as e:\n",
        "          print(f\"âŒ Error during chat: {e}\")\n",
        "          return f\"âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\"\n",
        "\n",
        "\n",
        "# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ\n",
        "chatbot = OpenAIChatbot()\n",
        "\n",
        "def chat_response(message, history):\n",
        "    return chatbot.chat(message)\n",
        "\n",
        "# Gradio Chat UI ã®ã¿\n",
        "def create_ui():\n",
        "    return gr.ChatInterface(\n",
        "        fn=chat_response,\n",
        "        title=\"ChatBotï¼ˆChatGPTåˆ©ç”¨ï¼‰\",\n",
        "        description=\"OpenAIã«ã‚ˆã‚‹æ—¥æœ¬èªãƒãƒ£ãƒƒãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\",\n",
        "        examples=[\n",
        "            \"INIADå·¥æ¥­æ ªå¼ä¼šç¤¾ã®å°±æ¥­è¦å®šã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\",\n",
        "            \"è£…ç½®Aã®åœæ­¢æ™‚ã®é©åˆ‡ãªå¯¾å¿œæ–¹æ³•ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\"\n",
        "        ],\n",
        "        submit_btn=\"é€ä¿¡\",\n",
        "        stop_btn=\"åœæ­¢\",\n",
        "    )\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "if __name__ == \"__main__\":\n",
        "    demo = create_ui()\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-qnYvpalFEQ"
      },
      "source": [
        "# 2.RAGã‚’å°å…¥ã—ã¦ã¿ã‚ˆã†\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€LangChainã¨Chromaã‚’ä½¿ã£ã¦PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šè¾¼ã¿ã€ãƒãƒ£ãƒ³ã‚¯åŒ–ã—ã€OpenAIã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ§‹ç¯‰ã—ã€ç°¡å˜ãªè³ªå•å¿œç­”ï¼ˆRAGï¼‰ã‚’å®Ÿè·µã—ã¾ã™ã€‚\n",
        "\n",
        "*å‹•ä½œç’°å¢ƒ: Google Colabã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmrVP39ilK0e"
      },
      "source": [
        "## 2.1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OifkbEWkFB2"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install langchain chromadb langchain-chroma langchain-openai pypdf tiktoken langchain-community requests gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q50rsFBClOpK"
      },
      "source": [
        "## 2.2. å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFyPQVx9kMCu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "import gradio as gr\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyM3LORtlsC7"
      },
      "source": [
        "## 2.3. PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFDJ_oavlb1x"
      },
      "outputs": [],
      "source": [
        "!wget -O rag_sample.pdf \"https://www.dl.dropboxusercontent.com/scl/fi/5q5wgjugmc7v0vc4youde/.pdf?rlkey=3mudbfkqjb7xj86hffmh962v1&st=toe9octw&dl=1\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uky-WiXlyiV"
      },
      "source": [
        "## 2.4. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã¨ãƒãƒ£ãƒ³ã‚¯åŒ–\n",
        "PDFã‚’èª­ã¿è¾¼ã¿ã€é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ã„ã‚„ã™ã„ã‚µã‚¤ã‚ºã«åˆ†å‰²ã—ã¾ã™ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvV_3gb_lt4N"
      },
      "outputs": [],
      "source": [
        "# PDFãƒ­ãƒ¼ãƒ€ãƒ¼ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—\n",
        "loader = PyPDFLoader(\"/content/rag_sample.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "# ãƒãƒ£ãƒ³ã‚¯åŒ–ã®è¨­å®šï¼ˆä¾‹: 1000æ–‡å­—ã®ãƒãƒ£ãƒ³ã‚¯ã€é‡è¤‡200æ–‡å­—ï¼‰\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20\n",
        ")\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(f\"Created {len(chunks)} chunks.\")\n",
        "\n",
        "for chunk in chunks:\n",
        "  print(f\"====================================\")\n",
        "  print(chunk)\n",
        "  print(f\"====================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQQyuWfxmEK_"
      },
      "source": [
        "## 2.5. ãƒãƒ£ãƒ³ã‚¯ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ãƒ™ã‚¯ãƒˆãƒ«ã®ä¿å­˜\n",
        "OpenAIEmbeddingãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’åŸ‹ã‚è¾¼ã¿ã€Chromaã«ä¿å­˜ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuXr8TX4l7Vp"
      },
      "outputs": [],
      "source": [
        "# åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    openai_api_base=openai_api_base,\n",
        "    openai_api_key=os.environ['OPENAI_API_KEY']\n",
        ")\n",
        "# Chromaãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã«æ°¸ç¶šåŒ–ï¼‰\n",
        "vectorstore = Chroma(\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_db/rag_sample\")\n",
        "\n",
        "# ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«DBã«è¿½åŠ \n",
        "vectorstore.add_documents(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwKhxJaDws8m"
      },
      "source": [
        "## 2.6.ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’ã—ã¦ã¿ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhpnFq3Bwwz5"
      },
      "outputs": [],
      "source": [
        "# è³ªå•ã®ä¾‹\n",
        "query = \"INIADå·¥æ¥­æ ªå¼ä¼šç¤¾ã®æ¦‚è¦ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\"\n",
        "\n",
        "# ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢\n",
        "docs = vectorstore.similarity_search(query, k=1)\n",
        "\n",
        "# çµæœã‚’è¡¨ç¤º\n",
        "for i, doc in enumerate(docs, 1):\n",
        "    print(f\"[{i}] {doc.metadata.get('source', '')}\")\n",
        "    print(doc.page_content[:300], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8GbG0WOmMSu"
      },
      "source": [
        "## 2.7. RAGã®ä½œæˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JaEqlPHmG8X"
      },
      "outputs": [],
      "source": [
        "# ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0.0,\n",
        "    openai_api_base=openai_api_base,\n",
        "    openai_api_key=os.environ['OPENAI_API_KEY']\n",
        ")\n",
        "\n",
        "# QAãƒã‚§ãƒ¼ãƒ³ã®è¨­å®š\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQonkA4gmnq0"
      },
      "source": [
        "## 2.8. RAGã®å®Ÿè¡Œ\n",
        "å®Ÿéš›ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè³ªå•ã‚’å…¥åŠ›ã—ã¦å›ç­”ã‚’å¾—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5feTmQbhmTWH"
      },
      "outputs": [],
      "source": [
        "print(\"============================= RAGã®å›ç­” =============================\")\n",
        "query = \"INIADå·¥æ¥­æ ªå¼ä¼šç¤¾ã®æ¦‚è¦ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\"\n",
        "rag_answer = qa.invoke(query)\n",
        "print(rag_answer[\"result\"])\n",
        "\n",
        "print(\"============================= LLM(ChatGPT)ã®å›ç­” =============================\")\n",
        "llm_answer = llm.invoke(query)\n",
        "print(llm_answer.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CehA-mhMH-iI"
      },
      "source": [
        "## 2.9.ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã¦å‡¦ç†ã™ã‚‹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLRMDJnlJ2iH"
      },
      "source": [
        "### 2.9.1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q2Sre2-IzCO"
      },
      "outputs": [],
      "source": [
        "# === è¨­å®š ===\n",
        "dropbox_url = \"https://www.dropbox.com/scl/fo/53hp5xxh8jo08t8ckhvyf/APEhI4MajStJbSYZClqvK0k?rlkey=4s5bwt71v39tfp4v075f4xi1l&st=n8dnqbjz&dl=1\"  # ç›´ãƒªãƒ³ã‚¯åŒ–\n",
        "zip_path = \"rag_handson.zip\"\n",
        "extract_dir = \"rag_handson\"\n",
        "\n",
        "# === 1. Dropboxã‹ã‚‰ZIPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ===\n",
        "print(\"Downloading ZIP from Dropbox...\")\n",
        "with requests.get(dropbox_url, stream=True) as r:\n",
        "    r.raise_for_status()\n",
        "    with open(zip_path, \"wb\") as f:\n",
        "        for chunk in r.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "print(\"Download complete.\")\n",
        "\n",
        "# === 2. ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡ ===\n",
        "print(\"Extracting ZIP...\")\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "print(\"Extraction complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q42qcoi_J9FH"
      },
      "source": [
        "### 2.9.2. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ã§ãƒ™ã‚¯ãƒˆãƒ«DBã«ä¿å­˜ã™ã‚‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbNvku14KHxo"
      },
      "outputs": [],
      "source": [
        "# === 1. PDFèª­ã¿è¾¼ã¿ & ãƒãƒ£ãƒ³ã‚¯åŒ– ===\n",
        "docs = []\n",
        "for path in Path(extract_dir).rglob(\"*.pdf\"):\n",
        "    try:\n",
        "        loader = PyPDFLoader(str(path))\n",
        "        docs.extend(loader.load())\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ {path.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
        "\n",
        "\n",
        "print(f\" {len(docs)} ãƒšãƒ¼ã‚¸ã®PDFã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚\")\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(f\" {len(chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã•ã‚Œã¾ã—ãŸã€‚\")\n",
        "\n",
        "# === 2. åŸ‹ã‚è¾¼ã¿ã¨ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä½œæˆ ===\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    openai_api_base=openai_api_base,\n",
        "    openai_api_key=os.environ['OPENAI_API_KEY']\n",
        ")\n",
        "vectorstore = Chroma(\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_db/rag_handson\"\n",
        ")\n",
        "vectorstore.add_documents(chunks)\n",
        "print(\"ãƒ™ã‚¯ãƒˆãƒ«DBã«ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-U9nA8oIFqG"
      },
      "source": [
        "## 2.10. Chatbotï¼ˆRAGï¼‰ã®èµ·å‹•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoQNa-dBn6O2"
      },
      "outputs": [],
      "source": [
        "# --- åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢åˆæœŸåŒ– ---\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    openai_api_base=openai_api_base,\n",
        "    openai_api_key=os.environ['OPENAI_API_KEY']\n",
        ")\n",
        "vectorstore = Chroma(\n",
        "    persist_directory=\"./chroma_db/rag_handson\",\n",
        "    embedding_function=embeddings\n",
        ")\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})  # ä¸Šä½3ä»¶ã‚’è¿”ã™\n",
        "\n",
        "\n",
        "# --- LLM åˆæœŸåŒ– ---\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0.0,\n",
        "    base_url=openai_api_base,\n",
        "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "\n",
        "# --- ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ---\n",
        "template = \"\"\"ä»¥ä¸‹ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨è³ªå•ã§ã™ã€‚\n",
        "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’ä½¿ã£ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n",
        "ã‚ã‹ã‚‰ãªã‘ã‚Œã°ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:\n",
        "{context}\n",
        "\n",
        "è³ªå•:\n",
        "{question}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "# --- RetrievalQA ãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆï¼ˆã‚½ãƒ¼ã‚¹å–å¾—ä»˜ãï¼‰ ---\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    chain_type=\"stuff\",\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "\n",
        "# --- å›ç­”é–¢æ•°ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚å«ã‚ã‚‹ï¼‰ ---\n",
        "def chat_response(message, history):\n",
        "    try:\n",
        "        result = qa_chain.invoke({\"query\": message})\n",
        "        answer = result.get(\"result\", \"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ã‚ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
        "        sources = result.get(\"source_documents\", [])\n",
        "\n",
        "        if sources:\n",
        "            formatted_sources = []\n",
        "            for i, doc in enumerate(sources):\n",
        "                title = doc.metadata.get(\"source\", f\"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ{i+1}\")\n",
        "                snippet = doc.page_content.strip().replace(\"\\n\", \" \").replace(\"ã€€\", \" \")\n",
        "                snippet = snippet[:300] + (\"â€¦\" if len(snippet) > 300 else \"\")\n",
        "                formatted_sources.append(f\"\"\"\n",
        "ã€{i+1}. {title}ã€‘\n",
        "{snippet}\n",
        "\"\"\")\n",
        "\n",
        "            sources_text = \"\\n---\\n\".join(formatted_sources)\n",
        "            full_response = f\"{answer}\\n\\nğŸ“„ **å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**\\n{sources_text}\"\n",
        "        else:\n",
        "            full_response = answer\n",
        "\n",
        "        return full_response\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return f\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\"\n",
        "\n",
        "\n",
        "# --- Gradio UI ---\n",
        "def create_ui():\n",
        "    return gr.ChatInterface(\n",
        "        fn=chat_response,\n",
        "        title=\"ChatBotï¼ˆRAG + ã‚½ãƒ¼ã‚¹è¡¨ç¤ºä»˜ãï¼‰\",\n",
        "        description=\"PDFãªã©ã‹ã‚‰æ§‹ç¯‰ã•ã‚ŒãŸãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’ç”¨ã„ãŸè³ªå•å¿œç­”ã€‚å‚ç…§å…ƒã‚‚è¡¨ç¤ºã—ã¾ã™ã€‚\",\n",
        "        examples=[\n",
        "            \"INIADå·¥æ¥­æ ªå¼ä¼šç¤¾ã®å°±æ¥­è¦å®šã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\",\n",
        "            \"è£…ç½®Aã®åœæ­¢æ™‚ã®é©åˆ‡ãªå¯¾å¿œæ–¹æ³•ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\"\n",
        "        ],\n",
        "        submit_btn=\"é€ä¿¡\",\n",
        "        stop_btn=\"åœæ­¢\",\n",
        "        type=\"messages\"\n",
        "    )\n",
        "\n",
        "# --- å®Ÿè¡Œ ---\n",
        "if __name__ == \"__main__\":\n",
        "    demo = create_ui()\n",
        "    demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCKKNrO6phzc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HJQ9LY48q5a5",
        "InNPx_oGGkQt",
        "SMMeugUpGpTl",
        "OREs7gMFGtS9",
        "FmrVP39ilK0e",
        "q50rsFBClOpK",
        "uyM3LORtlsC7",
        "6uky-WiXlyiV",
        "YQQyuWfxmEK_",
        "DwKhxJaDws8m",
        "e8GbG0WOmMSu",
        "CehA-mhMH-iI",
        "HLRMDJnlJ2iH",
        "q42qcoi_J9FH",
        "t-U9nA8oIFqG"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
