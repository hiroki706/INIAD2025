> 問　生成AIに代表されるようにAIの発達は著しく、将来を予測することは困難な状況にある。AIに対する規制でも、利用促進でも、期待でも、不安でも、我が国の対応についてでもテーマは自由ですので、現時点におけるAIに関する自分の意見を400字以上で記述して下さい。（特定の記事に対するコメントでも良い）（自分の意見の根拠を示す記述に努めて下さい）<br>
> AIに関するコメント

```
　2025年制定のAI新法について、事業者に課されるのは国への協力義務のみであり、罰則を一切伴わない。一見すると規制が緩やかで自由に開発できるように映るが、実際には「いつ厳罰が導入されるか分からない」という不確実性が残り、企業は巨額投資を躊躇する。国際法律事務所dentonsの調査でも、規制の曖昧さがAI投資を停滞させる「あいまいさの罠」が指摘されている。
　対照的にEU AI Actは、高リスク用途の義務違反で最大3,500万ユーロ又は世界売上高7％の制裁金を科すなど、行為を具体的に線引きし予見可能性を担保するハードローを採用した。
わが国でも、医療、車など高リスク分野でフォールバック手段など適切なリスク対策を備えずAIに全権を委ねる行為、モデル構造や学習データの利用目的、AI生成コンテンツであることなどの情報を開示しない行為を「不適切リスク対策・透明性違反」として、行政命令→過料→売上高連動課徴金へと段階的にエスカレートさせる制度設計が必要である。
　是正命令に従わない企業名を公表する可能性があることは、AI新法に記述されているが、これは労基法分野で再発防止に有効な抑止策として機能しており、AI領域でも有効な懲罰として機能する可能性がある。しかし資本力のある巨大企業には公表だけでは効果が限定的なため、EU型の懲罰金を併設すべきだ。
　無秩序は自由ではなく萎縮をもたらす。罰則付きでレッドラインを明示した秩序こそが、企業に安心感を与え、研究開発資源を大胆に投入させる土台となる。日本のAI法は次期改正で、高リスク管理不備と透明性義務違反に対し企業名公表＋売上高連動課徴金を規定するハードローへ進化させるべきである。これが成長と信頼を両立させる現実的な道だ。
```
