{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b09cd87",
   "metadata": {},
   "source": [
    "cnn_deep.ipynbから畳み込み層とプーリング層をさらに増やす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb86342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_1.\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow\n",
    "seedval = 13\n",
    "tensorflow.random.set_seed(seedval)\n",
    "np.random.seed(seedval)\n",
    "random.seed(seedval)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seedval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_2.\n",
    "IMAGESIZE = 256  #読み込んだ画像は(IMAGESIZE,IMAGESIZE)のサイズにリサイズする\n",
    "\n",
    "# ディレクトリ内の画像を読み込む\n",
    "# inputpath: ディレクトリ文字列, imagesize: 画像サイズ, type_color: ColorかGray\n",
    "def load_images(inputpath, imagesize, type_color):\n",
    "    imglist = []\n",
    "    filenamelist = []\n",
    "\n",
    "    for root, dirs, files in os.walk(inputpath):\n",
    "        for fn in sorted(files):\n",
    "            bn, ext = os.path.splitext(fn)\n",
    "            if ext not in [\".bmp\", \".BMP\", \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\", \".PNG\"]:\n",
    "                continue\n",
    "\n",
    "            filename = os.path.join(root, fn)\n",
    "\n",
    "            if type_color == 'Color':\n",
    "                # カラー画像の場合\n",
    "                testimage = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "                # サイズ変更\n",
    "                height, width = testimage.shape[:2]\n",
    "                testimage = cv2.resize(testimage, (imagesize, imagesize), interpolation = cv2.INTER_AREA)  #主に縮小するのでINTER_AREA使用\n",
    "                testimage = np.asarray(testimage, dtype=np.float64)\n",
    "                # 色チャンネル，高さ，幅に入れ替え．data_format=\"channels_first\"を使うとき必要\n",
    "                #testimage = testimage.transpose(2, 0, 1)\n",
    "                # チャンネルをbgrの順からrgbの順に変更\n",
    "                testimage = testimage[:,:,::-1]\n",
    "\n",
    "            elif type_color == 'Gray':\n",
    "                # グレースケール画像の場合\n",
    "                testimage = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "                # サイズ変更\n",
    "                height, width = testimage.shape[:2]\n",
    "                testimage = cv2.resize(testimage, (imagesize, imagesize), interpolation = cv2.INTER_AREA)  #主に縮小するのでINTER_AREA使用\n",
    "                # チャンネルの次元がないので1次元追加する\n",
    "                testimage = np.asarray([testimage], dtype=np.float64)\n",
    "                testimage = np.asarray(testimage, dtype=np.float64).reshape((imagesize, imagesize, 1))\n",
    "                # チャンネル，高さ，幅に入れ替え．data_format=\"channels_first\"を使うとき必要\n",
    "                #testimage = testimage.transpose(2, 0, 1)\n",
    "\n",
    "            imglist.append(testimage)\n",
    "            filenamelist.append(fn)\n",
    "    imgsdata = np.asarray(imglist, dtype=np.float32)\n",
    "\n",
    "    return imgsdata, filenamelist  # 画像リストとファイル名のリストを返す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_3.\n",
    "#%%\n",
    "### データ準備 ###\n",
    "print('*** Loading images ***')\n",
    "\n",
    "# 画像読み込みとラベル値作成\n",
    "# クラス0\n",
    "image0, filenames_image0 = load_images('./sundatabase_negative/', IMAGESIZE, 'Color')\n",
    "label0 = np.full(image0.shape[0], 0)    #画像数と同数のラベル値を含むリスト\n",
    "\n",
    "# クラス1\n",
    "image1, filenames_image1 = load_images('./sundatabase_positive/', IMAGESIZE, 'Color')\n",
    "label1 = np.full(image1.shape[0], 1)    #画像数と同数のラベル値を含むリスト\n",
    "\n",
    "\n",
    "# 画像，ラベル値，ファイル名それぞれ1つの配列にまとめる\n",
    "image_all = np.concatenate([image0, image1], axis=0)\n",
    "label_all = np.append(label0, label1)\n",
    "filename_all = filenames_image0 + filenames_image1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61811ce8-489f-43e4-bd7a-ab9ea3209675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_4.\n",
    "indices = np.array(range(image_all.shape[0]))\n",
    "image_train, image_test, label_train, label_test, index_train, index_test = train_test_split(image_all, label_all, indices, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c641b-d632-492c-a20a-dbfab636f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_5.\n",
    "print(indices)\n",
    "print(len(label_train))\n",
    "print(len(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa62dc2-ac3d-44a7-b017-2a0dd9fa1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_6.\n",
    "# testデータのファイル名リスト作成\n",
    "filenames_test = []\n",
    "for i in range(len(index_test)):\n",
    "    filenames_test.append(filename_all[index_test[i]])\n",
    "\n",
    "\n",
    "# 画像の画素値を0-1に正規化\n",
    "image_train /= 255.0\n",
    "image_test /= 255.0\n",
    "\n",
    "# ラベルをone hot vector形式に変換\n",
    "label_train_binary = to_categorical(label_train)\n",
    "label_test_binary = to_categorical(label_test)\n",
    "\n",
    "print('Loaded images: ' + repr(image_train.shape[0]) + ' for training and ' + repr(image_test.shape[0]) + ' for testing.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a072c1f-fc28-4b69-b9a8-99b4e4eb6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_7.\n",
    "### 画像分類モデル定義と学習処理の実行 ###\n",
    "print('*** Training ***')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# 層の数を増やした分類CNN（Sequential形式）\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional block\n",
    "model.add(Conv2D(32, (3, 3), strides=1, padding='same',\n",
    "                 activation='relu', input_shape=(IMAGESIZE, IMAGESIZE, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=4))\n",
    "\n",
    "# 2nd Convolutional block\n",
    "model.add(Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=4))\n",
    "\n",
    "# 3rd Convolutional block\n",
    "model.add(Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=4))\n",
    "\n",
    "# 4th Convolutional block\n",
    "model.add(Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=4))\n",
    "\n",
    "# Flatten → Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# モデル構造を表示\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f797d8-cec5-402b-ba69-6c54ef5523b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Cell_8.\n",
    "n_epochs=100\n",
    "val_split=0.2\n",
    "batch_size=128\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "history_file=\"history-w{}.csv\".format(IMAGESIZE)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "cl=CSVLogger(history_file)\n",
    "es=EarlyStopping(monitor='val_loss', patience=12, verbose=1)\n",
    "\n",
    "fit_log=model.fit(image_train, label_train_binary, batch_size=batch_size,\n",
    "                  epochs=n_epochs, validation_split=val_split,\n",
    "                  callbacks=[cl, es])\n",
    "#model14.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# training実行\n",
    "#training = model.fit(image_train, label_train_binary, epochs=100, batch_size=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb36a9-4d7a-4826-88db-71ed30e21529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_9.\n",
    "loss=fit_log.history['loss']\n",
    "val_loss=fit_log.history['val_loss']\n",
    "acc=fit_log.history['accuracy']\n",
    "val_acc=fit_log.history['val_accuracy']\n",
    "epoch=range(len(loss))\n",
    "\n",
    "plt.plot(epoch, loss, label='train')\n",
    "plt.plot(epoch, val_loss, label='valid')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epoch, acc, label='train')\n",
    "plt.plot(epoch, val_acc, label='valid')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b324d-2bdf-41a9-a104-cf160ddc2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_10.\n",
    "score=model.evaluate(image_test, label_test_binary, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3dcb37-5d45-4aa3-922a-7497eda0c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_11.\n",
    "y_test_pred=model.predict(image_test, verbose=0)\n",
    "ct = pd.crosstab(label_test_binary.argmax(axis=1),\n",
    "                 y_test_pred.argmax(axis=1))\n",
    "display(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11965f1-84dd-441c-84fc-cfc8474a6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_12.\n",
    "# testデータの分類結果をcsvファイルに書き出し\n",
    "f = open('./result_deep.csv', 'w')\n",
    "writer = csv.writer(f, lineterminator='\\n')\n",
    "\n",
    "savedata = ['filename', 'true_class', 'estimate_class', 'estimate_likelihood_max', 'estimate_likelihood_class0', 'estimate_likelihood_class1']\n",
    "writer.writerow(savedata)\n",
    "\n",
    "for i in range(len(image_test)):\n",
    "    savedata = [filenames_test[i], label_test[i], np.argmax(y_test_pred[i]), np.max(y_test_pred[i]), y_test_pred[i][0], y_test_pred[i][1]]\n",
    "    writer.writerow(savedata)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde29d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasienceict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
