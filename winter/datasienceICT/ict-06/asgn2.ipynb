{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb86342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEll_1.\n",
    "# -*- coding: utf-8 -*-\n",
    "#CNN_GANDAM.ipynb\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEll_2.\n",
    "IMAGESIZE = 128  #読み込んだ画像は(IMAGESIZE,IMAGESIZE)のサイズにリサイズする\n",
    "\n",
    "# ディレクトリ内の画像を読み込む\n",
    "# inputpath: ディレクトリ文字列, imagesize: 画像サイズ, type_color: ColorかGray\n",
    "def load_images(inputpath, imagesize, type_color):\n",
    "    imglist = []\n",
    "    filenamelist = []\n",
    "\n",
    "    for root, dirs, files in os.walk(inputpath):\n",
    "        for fn in sorted(files):\n",
    "            bn, ext = os.path.splitext(fn)\n",
    "            if ext not in [\".bmp\", \".BMP\", \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\", \".PNG\"]:\n",
    "                continue\n",
    "\n",
    "            filename = os.path.join(root, fn)\n",
    "\n",
    "            if type_color == 'Color':\n",
    "                # カラー画像の場合\n",
    "                testimage = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "                # サイズ変更\n",
    "                height, width = testimage.shape[:2]\n",
    "                testimage = cv2.resize(testimage, (imagesize, imagesize), interpolation = cv2.INTER_AREA)  #主に縮小するのでINTER_AREA使用\n",
    "                testimage = np.asarray(testimage, dtype=np.float64)\n",
    "                # 色チャンネル，高さ，幅に入れ替え．data_format=\"channels_first\"を使うとき必要\n",
    "                #testimage = testimage.transpose(2, 0, 1)\n",
    "                # チャンネルをbgrの順からrgbの順に変更\n",
    "                testimage = testimage[:,:,::-1]\n",
    "\n",
    "            elif type_color == 'Gray':\n",
    "                # グレースケール画像の場合\n",
    "                testimage = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "                # サイズ変更\n",
    "                height, width = testimage.shape[:2]\n",
    "                testimage = cv2.resize(testimage, (imagesize, imagesize), interpolation = cv2.INTER_AREA)  #主に縮小するのでINTER_AREA使用\n",
    "                # チャンネルの次元がないので1次元追加する\n",
    "                testimage = np.asarray([testimage], dtype=np.float64)\n",
    "                testimage = np.asarray(testimage, dtype=np.float64).reshape((imagesize, imagesize, 1))\n",
    "                # チャンネル，高さ，幅に入れ替え．data_format=\"channels_first\"を使うとき必要\n",
    "                #testimage = testimage.transpose(2, 0, 1)\n",
    "\n",
    "            imglist.append(testimage)\n",
    "            filenamelist.append(fn)\n",
    "    imgsdata = np.asarray(imglist, dtype=np.float32)\n",
    "\n",
    "    return imgsdata, filenamelist  # 画像リストとファイル名のリストを返す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEll_3.\n",
    "### データ準備 ###\n",
    "print('*** Loading images ***')\n",
    "\n",
    "# 画像読み込みとラベル値作成\n",
    "# クラス0\n",
    "image0, filenames_image0 = load_images('./sundatabase_negative/', IMAGESIZE, 'Color')\n",
    "label0 = np.full(image0.shape[0], 0)    #画像数と同数のラベル値を含むリスト\n",
    "\n",
    "# クラス1\n",
    "image1, filenames_image1 = load_images('./sundatabase_positive/', IMAGESIZE, 'Color')\n",
    "label1 = np.full(image1.shape[0], 1)    #画像数と同数のラベル値を含むリスト\n",
    "\n",
    "\n",
    "# 画像，ラベル値，ファイル名それぞれ1つの配列にまとめる\n",
    "image_all = np.concatenate([image0, image1], axis=0)\n",
    "label_all = np.append(label0, label1)\n",
    "filename_all = filenames_image0 + filenames_image1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61811ce8-489f-43e4-bd7a-ab9ea3209675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEll_4.\n",
    "indices = np.array(range(image_all.shape[0]))\n",
    "image_train, image_test, label_train, label_test, index_train, index_test = train_test_split(image_all, label_all, indices, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c641b-d632-492c-a20a-dbfab636f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_5.\n",
    "print(indices)\n",
    "print(len(label_train))\n",
    "print(len(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa62dc2-ac3d-44a7-b017-2a0dd9fa1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_6.\n",
    "# testデータのファイル名リスト作成\n",
    "filenames_test = []\n",
    "for i in range(len(index_test)):\n",
    "    filenames_test.append(filename_all[index_test[i]])\n",
    "\n",
    "\n",
    "# 画像の画素値を0-1に正規化\n",
    "image_train /= 255.0\n",
    "image_test /= 255.0\n",
    "\n",
    "# ラベルをone hot vector形式に変換\n",
    "label_train_binary = to_categorical(label_train)\n",
    "label_test_binary = to_categorical(label_test)\n",
    "\n",
    "print('Loaded images: ' + repr(image_train.shape[0]) + ' for training and ' + repr(image_test.shape[0]) + ' for testing.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a072c1f-fc28-4b69-b9a8-99b4e4eb6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_7.\n",
    "### 画像分類モデル定義と学習処理の実行 ###\n",
    "print('*** Training ***')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "\n",
    "# モデル定義（Sequential形式）\n",
    "model = Sequential()\n",
    "\n",
    "# 1st convolutional block\n",
    "model.add(Conv2D(32, (3, 3), strides=1, padding='same',\n",
    "                 activation='relu', input_shape=(IMAGESIZE, IMAGESIZE, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=4))\n",
    "\n",
    "# 2nd convolutional block\n",
    "model.add(Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=4))\n",
    "\n",
    "# Flatten and fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# モデル構造を表示\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20fec15-0d3d-43bd-b526-a672b53ff9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_8.\n",
    "# traininigの設定\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# training実行\n",
    "training = model.fit(image_train, label_train_binary, epochs=3, batch_size=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b2291-3c88-461f-b2c1-27f127d2293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_9.\n",
    "### 学習済みモデルの評価 ###\n",
    "print('*** Testing ***')\n",
    "\n",
    "# testデータの分類精度を表示\n",
    "scores = model.evaluate(image_test, label_test_binary, batch_size=5, verbose=0)\n",
    "print(\"%s on test data: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "#Confusion matrixを表示\n",
    "results = model.predict(image_test, batch_size=5, verbose=1)\n",
    "results_argmax = list(np.argmax(results, axis=-1))\n",
    "cmatrix = confusion_matrix(label_test, results_argmax)\n",
    "print('Confusion matrix:')\n",
    "print(cmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11965f1-84dd-441c-84fc-cfc8474a6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_10.\n",
    "# testデータの分類結果をcsvファイルに書き出し\n",
    "f = open('./result.csv', 'w')\n",
    "writer = csv.writer(f, lineterminator='\\n')\n",
    "\n",
    "savedata = ['filename', 'true_class', 'estimate_class', 'estimate_likelihood_max', 'estimate_likelihood_class0', 'estimate_likelihood_class1']\n",
    "writer.writerow(savedata)\n",
    "\n",
    "for i in range(len(image_test)):\n",
    "    savedata = [filenames_test[i], label_test[i], np.argmax(results[i]), np.max(results[i]), results[i][0], results[i][1]]\n",
    "    writer.writerow(savedata)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8136c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(IMAGESIZE, IMAGESIZE, 3))\n",
    "_ = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45334dd-ae31-4d6a-ba9f-8b779942e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_11.\n",
    "target_layer = model.get_layer(\"conv2d_3\")\n",
    "intermediate_model = Model(inputs=[model.inputs], outputs=[target_layer.output, model.output])\n",
    "label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b1be56-6253-442d-be11-40966bfb96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_12.\n",
    "idx_candidates = np.where(label_test.ravel() == 1)[0]\n",
    "\n",
    "if len(idx_candidates) == 0:\n",
    "    raise ValueError(\"No sample with label == 1 found in label_test!\")\n",
    "\n",
    "idx = int(idx_candidates[0])   # first occurrence\n",
    "print(idx)\n",
    "print(f\"Using sample index {idx} (label={label_test[idx]})\")\n",
    "\n",
    "# --- 2. Extract the corresponding image ---\n",
    "input_img = image_test[idx]\n",
    "\n",
    "# --- 3. Define intermediate model for Grad-CAM ---\n",
    "target_layer = model.get_layer(\"conv2d_3\")  # check the actual name in model.summary()\n",
    "\n",
    "intermediate_model = Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=[target_layer.output, model.output]\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28c3f0-4805-47b4-8cf2-65b6319f6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_13.\n",
    "# Suppose your Sequential model is named `model`\n",
    "# Find the name of the last convolutional layer\n",
    "import tensorflow as tf\n",
    "\n",
    "model.summary()  # Check layer names (e.g., 'conv2d_1')\n",
    "\n",
    "# Extract the output of the last conv layer\n",
    "last_conv_layer = model.get_layer('conv2d_3')  # update name as needed\n",
    "\n",
    "# Define an intermediate model that outputs both\n",
    "intermediate_model = tf.keras.Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=[last_conv_layer.output, model.output]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72b59d-f13f-4ed0-9eec-82c967517529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_14.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# --- Grad-CAM 計算 ---\n",
    "# 前処理済みの入力画像（NumPy）をTensorに変換\n",
    "input_img_tensor = tf.convert_to_tensor(input_img.reshape(1, IMAGESIZE, IMAGESIZE, 3), dtype=tf.float32)\n",
    "\n",
    "# 勾配を記録\n",
    "with tf.GradientTape() as tape:\n",
    "    # watch対象に指定\n",
    "    tape.watch(input_img_tensor)\n",
    "\n",
    "    # 特徴マップと最終出力を取得\n",
    "    conv_output, predictions = intermediate_model(input_img_tensor, training=False)\n",
    "\n",
    "    # 予測クラスのインデックスを決定\n",
    "    class_idx = tf.argmax(predictions[0])\n",
    "\n",
    "    # 目的クラスのスコア\n",
    "    loss = predictions[:, class_idx]\n",
    "\n",
    "# 勾配を計算（最後のConv層の出力に対する）\n",
    "grads = tape.gradient(loss, conv_output)\n",
    "\n",
    "# Global Average Pooling により重要度を計算\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "# 重み付き特徴マップの線形結合\n",
    "conv_output = conv_output[0]  # shape: (H, W, Channels)\n",
    "heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "\n",
    "# ReLU + 正規化\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap) + 1e-8\n",
    "\n",
    "# contrast stretching\n",
    "vmin, vmax = np.percentile(heatmap, [1, 99])\n",
    "heatmap = np.clip((heatmap - vmin) / (vmax - vmin + 1e-8), 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418682d-c2bb-4c40-944d-e42b5d4b68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_15.\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- ensure normalization and contrast enhancement ---\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "if np.max(heatmap) > 0:\n",
    "    vmin, vmax = np.percentile(heatmap, [1, 99])\n",
    "    heatmap = np.clip((heatmap - vmin) / (vmax - vmin + 1e-8), 0, 1)\n",
    "else:\n",
    "    heatmap = np.zeros_like(heatmap)\n",
    "\n",
    "# resize to match original image size\n",
    "heatmap = cv2.resize(heatmap, (64, 64))\n",
    "heatmap = np.power(heatmap, 0.7)  # smaller gamma → brighter\n",
    "\n",
    "# convert to color map\n",
    "heatmap_color = np.uint8(255 * heatmap)\n",
    "heatmap_color = cv2.applyColorMap(heatmap_color, cv2.COLORMAP_JET)\n",
    "\n",
    "# overlay\n",
    "superimposed_img = cv2.addWeighted(input_img.astype('uint8'), 0.6, heatmap_color, 0.4, 0)\n",
    "\n",
    "# show\n",
    "plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9b3f2-a223-4e8a-972d-8efdaea60be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_16.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def enhance_and_overlay(input_img, heatmap, output_size=(64, 64),\n",
    "                        gamma=0.5, blend_ratio=(0.5, 0.8)):\n",
    "    \"\"\"\n",
    "    Brightens and overlays a Grad-CAM heatmap on the original image.\n",
    "\n",
    "    gamma < 1.0 → brighter mid-tones\n",
    "    blend_ratio → (original_weight, heatmap_weight)\n",
    "    \"\"\"\n",
    "    if hasattr(heatmap, \"numpy\"):\n",
    "        heatmap = heatmap.numpy()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "    # Robust normalization\n",
    "    vmin, vmax = np.percentile(heatmap, [1, 99])\n",
    "    heatmap = np.clip((heatmap - vmin) / (vmax - vmin + 1e-8), 0, 1)\n",
    "\n",
    "    # Gamma correction to brighten midrange\n",
    "    heatmap = np.power(heatmap, gamma)\n",
    "\n",
    "    # Resize and colorize\n",
    "    heatmap_color = cv2.resize(heatmap, output_size)\n",
    "    heatmap_color = np.uint8(255 * heatmap_color)\n",
    "    heatmap_color = cv2.applyColorMap(heatmap_color, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Blend with original image\n",
    "    orig_w, cam_w = blend_ratio\n",
    "    superimposed = cv2.addWeighted(input_img.astype('uint8'),\n",
    "                                   orig_w, heatmap_color, cam_w, 0)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(superimposed, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return superimposed\n",
    "\n",
    "# --- usage ---\n",
    "_ = enhance_and_overlay(input_img, heatmap,\n",
    "                        output_size=(64, 64), gamma=0.4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasienceict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
