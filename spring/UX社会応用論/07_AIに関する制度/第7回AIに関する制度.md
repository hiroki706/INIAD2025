AIに関する制度
2025年5月29日
阪本　泰男

----------------
授業の構成（阪本担当部分）
　　　　（2025春学期）

・自治体DXの推進（各論）(4/10)

・アプリケーション分野における政策・制度(4/17)

・地域情報化の推進、ICT産業の動向（井上先生)(4/24)                                                                              

・サイバーセキュリティ制度論(5/8)

・自治体DXの進め方（田中先生）（5/15)

・個人情報保護法について（5/22)

・AIに関する制度



　　　　（2024秋学期）

 ・行政分野のDXの推進 

・政策：ICT政策の現状と課題

・制度・法律：情報法の展望

・経済：デジタルエコノミーの展望

・グローバル：グローバルなルール形成　

・データ活用で地域課題解決（吉田先生）

・自治体DX の推進（総論）
（注）知的財産法（著作権法など）

----------------
3
・AI倫理
・AIガバナンス
・AIと社会経済システム（Beyond Society 5.0など）
・AIと政治（民主主義など）
・AIと法律（憲法、民法、刑法、著作権法、個人情報保護法など）
・A Iと経済（労働市場、ビジネスモデル、DXなど）
・AIと技術・イノベーション（汎用AIなど）
・AIとリスク（偽・誤情報、サイバーセキュリティ、AI兵器など）
・A Iと利活用（自動運転、医療、教育など）
・A Iと国際連携・協調                               　    など
AIと社会と制度
（注）ICT社会応用論B（秋学期、選択科目）

----------------
AI倫理

----------------
トロッコ問題　（思考実験）
線路を走っていたトロッコの制御が不能になった。このままでは前方で作業中だった5人が猛スピードのトロッコに避ける間もなく轢き殺されてしまう。
 （ケース１） この時たまたまA氏は線路の分岐器のすぐ側にいた。A氏がトロッコの進路を切り替えれば5人は確実に助かる。しかしその別路線でもB氏が1人で作業しており、5人の代わりにB氏がトロッコに轢かれて確実に死ぬ。A氏はトロッコを別路線に引き込むべきか？
 （ケース２） A氏は線路の上にある橋に立っており、A氏の横にC氏がいる。C氏はかなり体重があり、もし彼を線路上につき落として障害物にすればトロッコは確実に止まり5人は助かる。だがそうするとC氏がトロッコに轢かれて死ぬのも確実である。C氏は状況に気づいておらず自らは何も行動しないが、A氏に対し警戒もしていないので突き落とすのに失敗するおそれは無い。C氏をつき落とすべきか？
 
（ケース１）
（ケース２）
A氏
B氏
C氏
（資料：Wikipedia、WIRED)
5
（注）功利主義（ベンサム）と義務論（カント）の対立

----------------
①帰結主義/功利主義　（ベンサム、ミル）
行為の正・不正は、その結果、関係者全員の幸福の合計が最大になるように、あるいは、「不幸が最少になるようにするべきだ」

②非帰結主義/義務論　（カント、ロールズ）
「結果の良し悪しとは関係なく、どのような事情によっても、してはならないことがあるのだ」
(1)「カント主義」： 私たちは 「あなたの行動指針が他の全員の行動指針となることを望めるように行為せよ」、「自分も他人も単なる道具として扱う事はせず、常に同時に目的として扱え」のような根本的な倫理的命令を理性を使うことによって発見することができるとされている。（人格主義）
(2)「自然法・自然権思想」： 私たちは 法律を定める前からすでに自然の法や神の法そして自然な権利（自然権）などが存在しているという考え方である。 他人の都合によって生命を奪われない権利、自由を侵害されない権利、財産を侵害されない権利などが代表的な自然権だとされる。（ルソーなど）

③徳倫理学　（アリストテレス、マイケル・サンデル）
帰結主義と義務論のどちらが倫理学説として有力かという枠組みで語られてきたが、決着がつく見込は薄い。最近ではこうした考え方の対立の枠組みそのものを疑う考え方も注目されている。
帰結主義も義務論も基本的には人の行為の正・不正や権利に注目している。しかし私たちの日常的な倫理的判断をよく見てみれば、私たちはある人の心の行為そのものよりもそれを行った当の人がどんな人かということを中心に評価を行っているように思われる。このように行為やルール、義務や権利よりもその人の性格のほうが重要であると考えるのが「徳倫理学」である。
 
 
（「情報倫理入門」　土屋俊　監修）
倫理学の主な考え方
6

----------------
人間/機械の二元論
　人間とAIの間にいまある決定的な相違点は何か？
　それはやがて消滅しうるか？　その消滅は何を意味するのか？

AIは心をもちうるか？
　① 理解力のあるAIは不可能か？
　② 感情のあるAIは不可能か？
　③ 意識のあるAIは不可能か？
（注）人間が特定の感情を抱くとき、体内で起こっているのは、脳のニューロンのシナプス間における微量の化学物質
　　　の伝達や、化学物質の急激な分泌という物理現象

懐疑派
・新井紀子氏　（AIは所詮コンピュータであり、意味を理解できず計算しか実行できない。コンピュータが人間並みの
　　　　知能を保つためには、人間の認識をすべて論理・統計・確率に置換しなければならないが、それは不可能だ。）
・西垣通氏（機械は、人間により設計されプログラム通りに動く他律システムであるが、人間は自律システム。
　　　　　　人工知能が人間の思考から生まれた以上、人間の認識や知性の限界を超えるのは不可能である。）

AI時代の入り口に立つ我々は、個人・社会・法がどう変容しつつあるか、それを踏まえてどのような人間像・
秩序像を構築するかについて、各人で塾考し、皆で熟議しなければならない。

（「AIは個人・社会・法に何をもたらすか」　宇佐美誠）
7

----------------
AIと情報倫理

古典哲学は、人間を「思考する存在」として定義し、人間にとっての最大の問題は、「いかに正しい方法で考えるのか」ということである。
AIの出現により、「思考する存在」が問われている。

AIをデザインするためには、私たちが何を求めているかを知る必要がある。
私たちは自分たちが何を本当に求めており、自分たちにとって何が本当の目的であり、自分たちが本当は何者なのかについて問わなければならない。 
AIをめぐる倫理問題

(1)AIシステムがもたらす二重のブラックボックス化
社会がブラックボックス化するとともに個人がブラックボックスとして扱われる。
個人のブラックボックス化は、人のモノ化を進行させ、アルゴリズムによる人間の支配を進展させることによって、人々の自由と自律、尊厳が損なわれる契機を生み出すのではないか。

(2)AI時代における働くことの意味
雇用における人間と技術の代替関係の先鋭化は、改めて「人間にとって労働とは何か」あるいは「人間労働の個人ならびに社会にとっての価値」について考え直す契機。

（注）アシロマAI原則、責任あるAIのためのモントリオール宣言、AIパートナーシップ理念、
　　　OECD AI原則

8

----------------
「基礎情報学」の立場から西垣通先生(東大名誉教授）の見解
情報とは、生命体の外部に実体としてあるものではなく、刺激を受けた生命体の内部に形成されるもの。
情報とは「生命体にとって意味作用をもつもの」
①情報の意味は、一般的には解釈者によって異なる。
②刺激ないし環境変化に応じ、あくまで自分自身の構成に基づいて自ら内部変容を続ける。その変容作用こそが
　意味作用である。
③変容の本質は、物質でもエネルギーでもなく、「形」であり、「パターン」である。

→ 情報とは、「それによって生物がパターンをつくりだすパターン」である。
情報の本質には、「生命体にとっての価値」が関わっており、これを生み出す意味作用の全体こそが、情報を物質やエネルギーから峻別する最重要点。

「オートポイエーシス理論」：生物は、自分で自分を作り上げる存在物。

（注）「アロポイエティック・システム」：内側からではなく外から構築されるシステム、自らで自らを作らない。


9

----------------
（「AIを活用した未来構想と地球倫理」　広井良典）
私たちは世界の無数の情報のうち私たちの生存にとって有用なものを選び出し、それに優先順位を与え、あるいは好き嫌いや好悪の感覚ないし感情と共に価値づけそれが世界の「意味」として立ち現れる。
一方、AIは脳の三つの機能の中で最後の部分（知に関わる部分）だけを切り離して機械にしたものだ。したがって純粋に論理や認識に関わる面― 記憶の容量や推論のスピードーなどでは人間をはるかに凌駕しうる反面、その土台にある価値判断や意思といった機能は持ち合わせておらず、AIはそれだけで独立することはできない。
10

----------------
　　　　　　　　　　AIに関する６つの倫理原則

①   アシロマのAI原則(2017年)
②   モントリオール宣言（2017年）
③   倫理に沿ったデザインで提示された一般原則(2017年)（「IEEE」）
④   人工知能、ロボット工学、自律的システムに関する声明(2018年)（「EGE」）
⑤   AIコードのための５つの包括的原則(2018年)（「AIKU」）
⑥   AIに関するパートナーシップの基本方針(2018年)（「パートナーシップ」）
11

----------------
　　　　　　　　　５つのAI倫理原則

AI倫理に最もよく似ているのが生命倫理である。
生命倫理の４原則は、AIが突きつける新たな倫理的課題に驚くほどよく適応する。
①   善行原則、②無危害原則、③自律原則、④正義原則
①   善行原則(Beneficence)：福利を促進する、尊厳を守る、地球を持続させる。
  各文書で最上位での位置付け
「モントリオール」、「IEEE」は、「福祉(well-being)」という言葉
「AIUK」、「アシロマ」は、「共通善」という言葉
「パートナーシップ」は、AIが出来る限り多くの人に対して利益を与える
「EGE」は、「人間の尊厳」と「持続可能性」原則を強調
 
②   無危害原則(Non-maleficence)：プライバシー、安全、そして「能力への警告(Capability Caution)
善行原則と無危害原則は、論理的に同一のように見えるが、生命倫理学とAI倫理学の文脈においては異なった原則
と考えるべき。
AI技術を過度に使用したり、誤って使用したりすることから生じる、多くの潜在的に否定的な帰結に対して、警告
を与えてもいる。
例：プライバシーの侵害、軍事AI技術拡大競争、AIの再帰的自己改善能力など
12
（「AIの倫理」ルチアーノ、フロリディ　2023年）より

----------------
③　自律原則(Autonomy)：決定する力（決定するかどうか）
我々自身のために保持する意思決定の力と、AIに委譲するものとの間で、バランスが取られなければならない。
人間が常に、どの決断を下すべきなのかということを決定する力を保持しているべきである。
しかし、この「決断するのか、委譲するのか、決定する能力」 は社会を通して等しく分配されているのではない。
 
④　 正義原則(Justice)：繁栄を促進し、そして連帯を守る
「アロシマ」は、AIによる「共有された利益」と「共有された繁栄」の両者必要
「EGE」は、「グローバル・ジャスティス」とAI技術による「利益の平等なアクセスに、貢献すべきである」
「AIKU」は、市民は「AIに伴って、心理的、感情的、経済的に、開花繁栄する」ことが出来る。
「パートナーシップ」は、「AIの発展によって影響を被る全ての者の利益を尊重する」
　正義原則に関連して、人々が直面したAIの位置付けが多様である点には注意が必要
 
⑤　説明可能性(Explicability)：理解可能性と説明責任を通じて、他の原則を可能にする。
「説明可能性」は、生命倫理学の枠組みをAI倫理学に適用した際に導くことの出来なかった原則である。
AIが利益をもたらし危害をもたらさないものであるためには(for AI to be beneficent and non-maleficent)、
我々は、AIが実際に社会に与える善あるいは悪について、理解することが出来なければならないのであるから、
この説明可能性原則は他の四つの原則を補うものである。
13

----------------
５つのAI倫理原則
14

----------------
人工知能の倫理に関する勧告
2021年11月23日　第41回ユネスコ総会採択
15
人工知能の倫理に関する勧告（仮訳）
https://www.mext.go.jp/unesco/009/1411026_00004.htm

----------------
各国のAI倫理原則の比較
（主な共通項目）

①人間の尊重
②多様性・包摂性の確保
③サスティナビリティ
④人間の判断の関与・制御可能性
⑤安全性・セキュリティ
⑥プライバシーの尊重
⑦公平性
⑧アカウンタビリティ
⑨透明性
(Main common items)

(1) Human dignity
(2) Ensuring diversity and inclusiveness
(3) Sustainability
(4)  Human intervention and controllability
(5) Safety and security
(6) Respect for privacy
(7) Fairness
(8) Accountability
(9) Transparency
Comparison of AI Ethical Principles in Different Countries
16

----------------
17
AI倫理の指針「AI8原則」の順守を　人工知能と社会　横山広美・東京大学教授（日経新聞　2023年5月）
https://www.nikkei.com/article/DGXZQOCD2732P0X20C23A4000000/

https://link.springer.com/article/10.1007/s00146-021-01323-9   （本文）


----------------
古典的人工知能：哲学的批判
（注）「人工知能の哲学入門」　鈴木貴之　勁草書房　2024
18

----------------
チューリングテスト
「知能」とは何か？
英国の数学者アラン・チューリングが「計算機械と知能」（1950年)で提案した架空のテスト。
知能を定義することは困難であるとした上で、質問者が、どちらの回答者が人間で、どちらの回答者がコンピュータか、を判断できるか？
チューリングテストに合格すれば、コンピュータは知能を持つと認定する。
19

----------------
中国語の部屋
チューリングテストに対する批判。
米国の哲学者ジョン・サールが考案した「中国語の部屋」の思考実験（1980年）
中国語の部屋は、中国語で書かれた文の意味を理解していないにもかかわらず、あたかも中国語を理解しているような振る舞いを示しているにすぎない。
20

----------------
フレーム問題
人工知能が現実世界において有用なものとなるためには、多数の知識の中から、ある状況において必要とされる知識を素早く特定することが必要である。しかしこれは極めて困難な問題である。
一般に、コンピュータプログラムが行為に関する推論を適切に実行するためには、行為によって何が変化し、何が変化しないかということが全て明示的な知識として表現されている必要がある。
ジョン・マッカーシーとパトリック・ヘイズ（1969年）
人工知能搭載のロボット「安全くん1号」は，人間の代わりに危険な作業をするロボットです．爆弾が仕掛けられている部屋から貴重な美術品を取り出してこなければなりません．安全くん1号は美術品の入った台車を押して美術品をとってきましたが，不幸なことに爆弾は台車にしかけられていたので，安全くんは爆発に巻き込まれてしまいました．
これは安全くん1号が，美術品を取り出すために荷車を押せばよいということは分かったのですが，そのことによって，爆弾も一緒に取り出してしまうということは分からなかったためでした
そこで，この問題を改良した「安全くん2号」が制作されました．安全くん2号は，美術品を取り出しに部屋に再び向かいました．しかし，美術品を運び出すには台車を動かせばよいと思いついたあと，台車を動かしたときの影響を
もし台車を動かしても，天井は落ちてこない． もし台車を動かしても，部屋の壁の色はかわらない． もし台車を動かしても，部屋の電気は消えない．  もし台車を動かしても，壁に穴があいたりしない． ‥‥‥‥ 
と順番に考えているうちに爆弾が爆発してしまいました
これは，べつに台車を動かしても天井は落ちくるという影響は生じないのですが，一応考えてみないと，影響があるかどうか分かりません．しかも，台車を動かしても影響を受けないことは無数にあるため，考えるのに時間がかってしまうためです．
「爆弾と美術品以外の関係のないことは考えなくてもいいのではないか？」と思うかもしれません．しかし，この場合も，壁，天井，電気などありとあらゆることについて，爆弾や美術品と関係があるかどうかを考えているうちに爆弾が爆発してしまいます．このように，たとえどんな方法をとっても，途中で世の中のありとあらゆることについて考える必要が生じてしまいます．これがフレーム問題です
21

----------------
22
（東京大学　松尾　豊）
http://ymatsuo.com/DL.pdf

シンボルグラウンディング問題

----------------
問　現在のAIは、古典的AIが直面した困難を克服したのか？
シンボルグラウンディング問題（意味理解の問題）
大規模言語モデルは、みずから世界と接触することなしに、語と語の間の確率的関係だけを学習し、それによって言語使用が可能になっている。
解釈①：LLMは、言語を適切に使用するためには、語と語の確率的関係を理解すれば十分であり、
　　　　言語使用には、意味理解は必要ない。
解釈②：意味理解とは言語と世界の関係を理解することではなく、語を語の関係を理解することである。

→言語使用や意味理解とは何か、両者はどのような関係にあるかといったことについて再考が必要。

LLMの手法が有効でないのは言語使用のどのような領域か、LLMが有効な領域においても、人間とLLMの原理の違いが重大な違いをもたらすことはあるのか？

→言語使用という現象を理解するための理論的枠組みを再検討。
23

----------------
フレーム問題（状況理解の問題）

深層ニューラルネットワークは、複雑な数理モデルによって、しかるべき特徴量を関係づけることが出来るために、古典的AIでは扱うことの出来ない問題を扱える。
これにより、コード化不可能性の問題やフレーム問題は解決できるか？→それほど、単純ではない。
現在は、コード化不可能性の問題のうち、深層ニューラルネットワークによる解決が可能なのは、領域が明確に限定された性質（絵画の美しさなど）に関する問題だけ。
フレーム問題を深層ニューラネットワークによって解決を試みる際には、入力だけでなく、出力をどのように設定するかも問題になる。

→膨大な量の試行錯誤に依存することなく、状況に応じた柔軟な行動をとることのできる人工エー　　ジェントを作成することは可能か？
　AI研究は、現実世界における営みであるため、計算資源や学習に利用できる時間などに関する制約　が存在する。フレーム問題を回避できる人工エージェントをそれらの制約の下で作成する方法は？

→深層ニューラルネットワークにおいて、フレーム問題がどのような形で生じるか自体をまず明らか　にする必要がある。
24
（注）コード化不可能性：哲学においては、美、善、合理性といった性質はコード化不可能であり、大きさや重さと
　　　　　　　　　　　　いった物理的性質とは根本的に異なる性質をもつと論じられてきた。

----------------
https://www.toyo.ac.jp/link-toyo/social/AI_philosophy/

（参考）

----------------
AI・ロボットと法
AI, Robots and the Law
26

----------------
（総論）
・「自由、安全、正義、平等などの規範」との関係
・「労働市場、所得分配、職務上必要とされる能力」との関係

・個人が自律した人格を有する人間像、意思に基づいて行われた行為の責任をその個人に帰属させる
　という世界観が、現在の法の前提になっている。
　その前提で、権利能力・法人・基本的人権といった法秩序の基礎になる概念、あるいは私的自治や　
　過失責任主義といった基本的な原理原則は組み立てられている。
　　（注）近代私法の三大原則　①権利能力平等の原則、②私的所有権絶対の原則、③私的自治の原則

　①このような人間像・世界観は、ロボット・AIの登場によって維持できなくなるのではないか？

　②先程の人間像・世界観がフィクションであることは、少なくとも現代の法は自覚した上で部分的　
　　な修正で対応してきたのであり、ロボット・A Iも同じように対応すれば足りるのではないか？
AI・ロボットと法
（AIと社会と法　有斐閣）
AI・ロボットと法
27

----------------
我妻栄は、「近代法思想における自由平等の原理の具体的顕現」が「個人の財産権の絶対・個人意思の自治（契約の自由）・過失責任」だと位置付けた。

（注）近代私法の三大原則（封建的支配から個人を解放するための原理）
①権利能力平等の原則（国籍、職業、性別などにかかわらず、全ての人は等しく権利義務の帰属主体となる資格（権利能力）を有する。
②私的所有権絶対の原則（所有権は、何ら人為的拘束を受けず、侵害するあらゆる他人に対して主張することができる完全な支配権）
③私的自治の原則（私人間の法律関係は、一切個人の自主的決定にまかせ、国家がこれに干渉してはならないとする原則）
現代になり自由主義（主として経済領域における）の問題的が指摘されるようになり、徐々に変容を見せている。
（AIと社会と法　有斐閣）
28

----------------
・近代の法システムが前提としてきたのは、「強い個人」（判断能力があって合理的で、自分
　が決めたことをやれるタイプの人間）しかし、現実は「弱い個人」。
　均質な自律的個人からなる自由で平等な社会という基本原則を考えてきた。
　その建前は、建前として維持できる部分とその通用力が限定されてきた部分があるのではないか？
 
・民事法：契約当事者としての個人、これも自律的な個人というフィクションを前提に、社会法や消費者　
　法によって、支援したり修正したりして対応するのが現在の民事法。
　データの取引、特にデータの取集ということを考えると、個人を単位にするということは、フィクショ　
　ンであることが明確になりつつある。


・刑事法：近代を基礎付ける心身二元論と主客二元論（主体と客体を完全分離）というアイデアに立脚し、
　主体の自由意志に基づく行為に対して刑事制裁を科すことで望ましくない行為を抑止して、社会秩序等　
　を維持する構図を採用。今や主体と客体の区別が消滅しつつあるのではないか？
　人間の存在を所与の前提としてきた既存の刑事法理論の限界が露呈しつつあるのではないか？


○ AIも今のところは人間あるいは社会が使う道具である以上、法が実現しようとしてきた根本的な価値が　
　変わるものではないことを前提に、その実現の仕方が、それぞれの法分野で変わってくるという意味での　
　パラダイムシフトが起きている。


 
（AIと社会と法　有斐閣）　（AIで変わる法と社会　岩波書店）
（注）人間とAIを搭載した機械とが協調動作をするとき、そこで意思決定し、行為している主体は誰なのだろうか。
29

----------------
○ どういうリスクの配分、責任の配分をするとAIが適切に社会に受け入れられるかという問題。

・人間の自由の問題として、AIを利用しない自由あるいはAIを拒否する自由があるのかという問題　
　が出てくる。
 
・AIでサポートなりエンハンスされていくと、人間がAIに依存していって自由が奪われるのではないか？


（AIの透明性をどう確保するのか？）
 
①自律性と制御可能性
「自律的」とは、人間から独立にロボット・AIが判断すること。自律的の中にも程度の差がある。
自律性の程度は、事故の際に背後にいる人間にロボット・A Iの行動から生じた責任を負わせることができるかという問題と関連する。

②透明性と説明可能性
ブラックボックス化してしまう場合が多い。
透明性・説明可能性が確保できるのか、できないのであれば、利用制限すべきではないかという議論。


30

----------------
（AIの学習データの適切性の問題）
・学習した元のデータと、それを使う場所等が異なると、正しい学習結果にならない。
　データがクラウド上にある場合は、どうなるのか？（国境を越えるなど）


（現在のAIも直面する課題）（前述）

シンボルグラウンディング問題
記号接地問題：「記号で指し示されるものをAIがどのように認識するかという問題」。
記号（シンボル）が概念に接地（グラウンディング）されることなしには、記号処理が意味をなさないことを議論。


「フレーム問題」：
考慮すべき枠（ルール）が決まれば、AIを生かせるが、枠が決まらないような世界では上手くいかない。

31

----------------
32
A I 制 度

----------------
AI戦略会議　（2023年5月〜　　）
https://www8.cao.go.jp/cstp/ai/ai_senryaku/ai_senryaku.html


----------------
34
AI制度研究会
https://www8.cao.go.jp/cstp/ai/ai_kenkyu/ai_kenkyu.html
第１回　2024年8月

----------------
https://www8.cao.go.jp/cstp/ai/ai_senryaku/9kai/shiryo2-2.pdf

https://www8.cao.go.jp/cstp/ai/ai_senryaku/9kai/shiryo2-1.pdf　（本文）

35

----------------
36

----------------
37

----------------
38
ハードロー(hard law)とソフトロー(soft law)
ハードロー：国家・自治体・企業・個人に対して強制力を持つ規則。 法律・法令・条例など。
                      （例）EU：AI規制法
（例）日本：AI事業者ガイドライン
（参考）

----------------
39
（注）AI 提供者等が遵守すべき事項（例えば AI 搭載製品の安全基準）については、具体的な議論の積上げ が必要
（注）

----------------
40

----------------
41

----------------
人工知能関連技術の研究開発及び活用の推進に関する法律（AI法）
https://www.cao.go.jp/houan/217/index.html

(2025年5月28日　国会成立）
https://www.cao.go.jp/houan/pdf/217/217anbun_2.pdf　（法律）


----------------
人工知能関連技術の研究開発及び活用の推進に関する法律（AI法）(2025年5月28日　国会成立）

----------------
（目的） 
第一条　この法律は、人工知能関連技術が我が国の経済社会の発展の基盤となる技術であることに鑑み、人 工知能関連技術の研究開発及び活用の推進に関する施策について、基本理念並びに人工知能関連技術の研究開発及び活用の推進に関する基本的な計画の策定その他の施策の基本となる事項を定めるとともに、人工知能戦略本部を設置することにより、科学技術・イノベーション基本法（平成七年法律第百三十号）及びデジタル社会形成基本法（令和三年法律第三十五号）その他の関係法律による施策と相まって、人工知能関連技術の研究開発及び活用の推進に関する施策の総合的かつ計画的な推進を図り、もって国民生活の 向上及び国民経済の健全な発展に寄与することを目的とする。
（定義） 
第二条　この法律において、「人工知能関連技術」とは、人工的な方法により人間の認知、推論及び判断に係る知的な能力を代替する機能を実現するために必要な技術並びに入力された情報を当該技術を利用して処理し、その結果を出力する機能を実現するための情報処理システムに関する技術をいう。
第一章　総則（第一条－第十条）
第二章　基本的施策（第十一条－第十七条）
第三章　人工知能基本計画（第十八条）
第四章　人工知能戦略本部（第十九条－第二十八条）
　附則

----------------
（基本理念） 
第三条　人工知能関連技術の研究開発及び活用の推進は、科学技術・イノベーション基本法第三条に定める 科学技術・イノベーション創出の振興に関する方針及びデジタル社会形成基本法第二章に定める基本理念のほか、この条に定める基本理念に基づいて行うものとする。
 
２　人工知能関連技術の研究開発及び活用の推進は、人工知能関連技術が、その適正かつ効果的な活用によって行政事務及び民間の事業活動の著しい効率化及び高度化並びに新産業の創出をもたらすものとして経済社会の発展の基盤となる技術であるとともに、安全保障の観点からも重要な技術であることに鑑み、 我が国において人工知能関連技術の研究開発を行う能力を保持するとともに、人工知能関連技術に関する産業の国際競争力を向上させることを旨として、行うものとする。 

３　人工知能関連技術の研究開発及び活用の推進は、人工知能関連技術の基礎研究から国民生活及び経済活動における活用に至るまでの各段階の関係者による取組が相互に密接な関連を有することに鑑み、これら の取組を総合的かつ計画的に推進することを旨として、行うものとする。
 
４　人工知能関連技術の研究開発及び活用は、不正な目的又は不適切な方法で行われた場合には、犯罪への利用、個人情報の漏えい、著作権の侵害その他の国民生活の平穏及び国民の権利利益が害される事態を助長するおそれがあることに鑑み、その適正な実施を図るため、人工知能関連技術の研究開発及び活用の過程の透明性の確保その他の必要な施策が講じられなければならない。
 
５　人工知能関連技術の研究開発及び活用は、我が国及び国際社会の平和と発展に寄与するものとなるよう、国際的協調の下に推進することを旨とし、我が国が人工知能関連技術の研究開発及び活用に関する国際協力において主導的な役割を果たすよう努めるものとする。

----------------
（調査研究等） 
第十六条　国は、国内外の人工知能関連技術の研究開発及び活用の動向に関する情報の収集、不正な目的又 は不適切な方法による人工知能関連技術の研究開発又は活用に伴って国民の権利利益の侵害が生じた事案の分析及びそれに基づく対策の検討その他の人工知能関連技術の研究開発及び活用の推進に資する調査及び研究を行い、その結果に基づいて、研究開発機関、活用事業者その他の者に対する指導、助言、情報の提供その他の必要な措置を講ずるものとする。

----------------
AIに関する国際的な取り組み

----------------
2016年4月　　G7香川・高松情報通信大臣会合（「AI開発原則」を提示。国際的に検討することに合意）

2019年5月　　「AIに関するOECD原則」採択（42ヵ国）

2019年6月　　G20大阪サミット （「G20  AI原則」）

2021年4月　　EU 「人工知能に関する調和の取れたルールを定める規則」の提案

2022年11月　 生成AI ChatGPTが公開

2023年5月　 「AI戦略会議」の開催（日本）

2023年5月　　G７広島サミット「広島AIプロセス」

2023年10月　  米国　生成AIに関する大統領（2025年1月　トランプ大統領　大統領令　撤回）

2023年11月　  英主催「AI安全性サミット」　(2024年5月　第２回　韓国開催）

2024年3月　　国連総会　AIに関する決議

2024年5月　　EU   AI法成立

2024年9月       国連AIハイレベル諮問機関　最終報告書

2025年2月　　仏主催「AIアクションサミット」（第3回目）

2025年5月　　日本　AI法成立
48

----------------
（2024年8月時点）
（AI戦略会議）
（総括表）

----------------
E U

----------------
51
欧州AI規制法等の動き
2021年4月　欧州委員会は、「AI規則案」を提案
2023年6月　AI規則案に生成AIに関する条項が追加されて、欧州議会で可決
2024年5月17日　　欧州評議会、「AI国際条約」を採択
2024年5月21日　「欧州(EU)AI規制法」の成立（欧州委員会、EU理事会、欧州議会）
2024年8月1日　AI規制法の施行
　　　　　　　　規制内容に応じ2030年12月までに段階的に施行

（注）AI規則案ではこの4分類とは別に、基盤モデルや生成AIに関する条項も設けられています。特に、生成AIとして利用される基盤モデルの提供者には、「コンテンツがAIによって生成されたと開示すること」「違法コンテンツの生成や基本的人権の侵害が起こらないようにモデルの学習・設計・開発すること」「著作権で保護されているデータの利用について十分に詳細な要約を文書化・公開するといった義務を負うこと」が定められています。
（生成AIの法的リスクと対策）

----------------
https://www.soumu.go.jp/main_content/000761967.pdf

52
EU
(2021年4月）

----------------
53

----------------
「ＡＩの研究開発の原則」
AI R&D Principles 
54

----------------
　・　ＯＥＣＤプライバシーガイドライン、同・セキュリティガイドライン等を参考に、関係ステークホルダーの参画を得つつ、　
　 研究開発に関する原則を国際的に参照される枠組みとして策定することに向け、検討に着手することが必要。
　・　研究開発に関する原則の策定に当たっては、少なくとも、次に掲げる事項をその内容に盛り込むべき。
①　透明性の原則
　　　ＡＩネットワークシステムの動作の説明可能性及び検証可能性を確保すること 。
②　利用者支援の原則
　　　ＡＩネットワークシステムが利用者を支援するとともに、利用者に選択の機会を適切に提供するよう配慮すること 。
③　制御可能性の原則
　   人間によるＡＩネットワークシステムの制御可能性を確保すること 。
④　セキュリティ確保の原則
　    ＡＩネットワークシステムの頑健性及び信頼性を確保すること 。
⑤　安全保護の原則
　    ＡＩネットワークシステムが利用者及び第三者の生命・身体の安全に危害を及ぼさないように配慮すること 。
⑥　プライバシー保護の原則
　    ＡＩネットワークシステムが利用者及び第三者のプライバシーを侵害しないように配慮すること 。
⑦　倫理の原則
　　　ネットワーク化されるＡＩの研究開発において、人間の尊厳と個人の自律を尊重すること。
⑧　アカウンタビリティの原則
　　　ネットワーク化されるＡＩの研究開発者が利用者等関係ステークホルダーへのアカウンタビリティを果たすこと。　
「ＡＩの研究開発の原則」の策定について
（2016年4月　G7香川・高松情報通信大臣会合）　
（総務省）
55

----------------
G20 AI原則 
附属書
G20は以下のセクション1の信頼できるAIのための責任あるスチュワードシップに関する原則を支持し、セクション2の勧告について留意する。
 
1. 信頼できるAIのための責任あるスチュワードシップに関する原則 

1.1 包摂的な成長、持続可能な開発及び幸福 
ステークホルダーは、人間の能力の増強や創造性の向上、少数派の包摂の促進、経済・社会・性別などにおける不平等の改善、自然環境の保護を通じ、包摂的な成長、持続可能な開発及び幸福の活性化のような人々と地球にとって有益な結果を追求することにより、信頼できるAIのための責任あるスチュワードシップに積極的に取り組むべきである。 
1.2 人間中心の価値観及び公平性 a) AIのアクターは、AIシステムのライフサイクルを通じ、法の支配、人権及び民主主義的な価値観を尊重すべきである。これらには、自由や尊厳、自主自律、プライバシーとデータの保護、無差別と平等、多様性、公平性、社会正義、国際的に認知された労働権が含まれる。 b) このため、AIのアクターは、人間による最終的な意思決定の余地を残しておくことなど、状況に適した形で且つ技術の水準を踏まえたメカニズムとセーフガードを実装すべきである。 
1.3 透明性及び説明可能性 
AIのアクターはAIシステムに関する透明性と責任ある開示に取り組むべきである。このため、AI のアクターは下記の目的で、状況に適した形で且つ技術の水準を踏まえた有意義な情報提供を行うべきである: 
ⅰAIシステムに関する一般的な理解を深めること。
 ii. 職場におけるものを含め、AIシステムの関与をステークホルダーに認識してもらうこと。
 iii. AIシステムに影響される者がそれから生じた結果を理解できるようにすること。 iv. 要因に関する明快且つ分かりやすい情報、並びに予測、勧告あるいは判断の根拠となった論理に基づいて、AIシステムから悪影響を受けた者がそれによって生じた結果に対して反論することができるようにすること。 
1.4 頑健性、セキュリティ及び安全性 a) AIシステムは、通常の使用や予見可能な使用及び誤用あるいはその他の悪条件下においても正常に機能するとともに、不合理な安全リスクをもたらすことがないよう、そのライフサイクル全体にわたって頑健且つセキュリティが高く、安全なものであるべきである。 
b) このため、AIシステムの出力に関する分析と問合せに対する対応を可能とするため、AIのアクターは、データセットやプロセス、AIシステムがそのライフサイクルに行った決定に関することも含め、状況に適した形で且つ技術の水準を踏まえたトレーサビリティを確保すべきである。
(2019年6月）
56
https://www.mofa.go.jp/mofaj/gaiko/g20/osaka19/pdf/documents/jp/annex_08.pdf


----------------
c) AIのアクターは、その役割や状況、能力に基づき、系統化されたリスク管理のアプローチをA Iシステムのライフスタイルの各段階に適用することにより、プライバシーやセキュリティ、安全 性、バイアスといったAIシステムに関するリスクに絶え間なく対処していくべきである。 
1.5 アカウンタビリティ
 AIのアクターは、その役割と状況に基づき、また、技術の水準を踏まえた形で、AIシステムが適正に機能していることと上記の原則を順守していることについて、アカウンタビリティを果たせるようにすべきである。 
2. 信頼できるAIのための国内政策と国際協力 

2.1 AIの研究開発への投資 a) 信頼できるAIの実現に向けたイノベーションを促進するため、各国政府は、学際的な取組を含め、技術的に困難な課題やAIの社会的・法的・倫理的な影響と政策課題に焦点を当てた調査研究及び研究開発について、長期的な公共投資を検討し、また民間投資を奨励すべきである。 b) また、各国政府は、不適切なバイアスがなく、相互運用性と技術標準の利用を増進するため、十分な代表性を有し、且つプライバシーとデータの保護を順守する開かれたデータセットについて、公共投資を検討し、また民間投資を奨励すべきである。 
2.2 AIのためのデジタル・エコシステムの整備 
各国政府は、信頼できるAIのためのデジタル・エコシステムとそれへのアクセスを整備すべきである。このエコシステムには、デジタル・テクノロジーとデジタルインフラ、必要に応じてAI知識を共有するためのメカニズムが含まれる。これに関連し、各国政府は、データ・トラストのような、安全、 公平、適法且つ倫理的にデータを共有するためのメカニズムに対する支援を検討すべきである。 
2.3 AIを推進するための政策環境の整備 a) 各国政府は、信頼できるAIシステムが研究開発の段階から展開・稼働の段階への迅速な移行を支援するための政策環境を整備すべきである。このため、政府は必要に応じてAIシステムの実験と拡張のための制御された環境下での実証実験の活用を検討すべきである。 b) 各国政府は、信頼できるAIの実現に向けたイノベーションと競争を奨励するため、必要に応じ、AIシステムに適用される政策及び規制の枠組みやその評価メカニズムの見直しと改正を行うべきである。 
57

----------------
2.4 人材育成及び労働市場の変化への準備 a) 各国政府は、仕事の世界と社会全体の変化に備えるためにステークホルダーと緊密に協働すべきである。政府は人々に必要なスキルを習得させるなどして、人々が広い範囲で適用されるAIシステ ムを効果的に利用し、それとうまく関わることができるようにすべきである。 b) 各国政府は、就労期間を通じたトレーニング・プログラムや離職を余儀なくされた者への支援、労働市場における新たな機会へのアクセスなどを通じ、AIの普及がもたらす労働市場の変化が労働者にとって公平なものであるよう万全を期すため、社会的な対話などの措置を講じていくべきである。 
c) 各国政府はまた、職場におけるAIの責任ある利用の推進、労働者の安全及び仕事の質の向上、起業家精神と生産性の向上、AIの恩恵の幅広く且つ公平な共有が確保されるようにするため、ステークホルダーと密接に協働すべきである。 
2.5 国際協力 a) 開発途上国を含め、各国政府は、ステークホルダーとともに、これらの原則を推進し、信頼できるAIのための責任あるスチュワードシップを促進するために積極的に協力すべきである。 
b) 各国政府は、必要に応じてOECDやその他の世界的及び地域的な国際場裏において、AI知識 の共有を推進するために協働すべきである。政府はAIに関する長期的な専門知識を蓄積するために、国際的且つ分野横断的であり、マルチステークホルダーによる開放的な取組みを奨励すべきである。 
c) 各国政府は、相互運用性があり、且つ信頼できるAIの実現のため、マルチステークホルダーの合意に基づく世界的な技術基準の開発を推進すべきである。 
d) 各国政府はさらに、AIの研究開発や展開を測定すると共に、これらの原則の履行の状況を評価する際に根拠となる証拠を収集するため、国際的に比較可能な測定基準の開発とその利用を奨励すべきである。 

58

----------------
59

----------------
国連　AIハイレベル諮問機関　最終報告書「人類のためのAIの統治」
　　　　　　　　　　　　　　　　　　　　　　　　　　　（2024年9月）
https://www.un.org/sites/un2.un.org/files/governing_ai_for_humanity_final_report_en.pdf

This groundbreaking report outlines a blueprint for addressing AI-related risks and sharing its transformative potential globally, including by: 
• Urging the UN to lay the foundations of the first globally inclusive and distributed architecture for AI governance based on international cooperation; 
• Proposing seven recommendations to address gaps in current AI governance arrangements; 
• Calling on all governments and stakeholders to work together in governing AI to foster development and protection of all human rights.
この画期的な報告書では、AI関連のリスクに対処し、その変革の可能性を世界的に共有するための青写真が概説されています。具体的には、
• 国連に対し、国際協力に基づくAIガバナンスのための世界初の包括的かつ分散型アーキテクチャの基礎を築くことを促すこと、
• 現在のAIガバナンス体制におけるギャップに対処するための7つの提言を行うこと、
• すべての政府およびステークホルダーに対し、AIのガバナンスにおいて協力し、すべての基本的人権の開発と保護を促進することを呼びかけること、
https://www.un.org/ai-advisory-body


----------------
AIが発達した時の社会経済システムは？
AGI（汎用人工知能） ？

ASI（人口超知能）　?

----------------
（AI社会を支える次世代情報通信基盤の実現に向けた戦略　総務省）
（参考）
https://www.soumu.go.jp/main_content/000965078.pdf

