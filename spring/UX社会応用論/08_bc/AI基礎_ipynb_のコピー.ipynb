{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYZ1lSXUaV6r"
      },
      "source": [
        "# 0. 必要なデータ、モジュールのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MmfKP2e9sAmw"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import set_random_seed\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Black.ttc'\n",
        "ipaex_gothic = matplotlib.font_manager.FontProperties(fname=font_path)\n",
        "\n",
        "# グラフのフォントに適用\n",
        "plt.rcParams['font.family'] = ipaex_gothic.get_name()\n",
        "\n",
        "!wget -O data.zip https://www.dropbox.com/scl/fi/nr1caawmfnd97g1lteokh/data.zip?rlkey=02fow7tv7eoywq1p44wou2xv8&st=h9kq01bu&dl=0\n",
        "!unzip /content/data.zip\n",
        "\n",
        "# 学習データの読み込み\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# テストデータの読み込み\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUgUNYBSMmrE"
      },
      "source": [
        "# 1. 条件分岐（if文）を用いた予測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMrRUn4aNgjI"
      },
      "source": [
        "## 1-1. 条件の設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H-MUI_SSVOy"
      },
      "outputs": [],
      "source": [
        "# データ（修正後カラム名）\n",
        "data = [\n",
        "    {\"GPA\": 2.0, \"Programming\": 75, \"Internship\": 1, \"Recruit_score\": 69},\n",
        "    {\"GPA\": 1.6, \"Programming\": 45, \"Internship\": 0, \"Recruit_score\": 43},\n",
        "    {\"GPA\": 3.2, \"Programming\": 97, \"Internship\": 1, \"Recruit_score\": 64},\n",
        "    {\"GPA\": 3.2, \"Programming\": 66, \"Internship\": 1, \"Recruit_score\": 77},\n",
        "    {\"GPA\": 3.6, \"Programming\": 41, \"Internship\": 0, \"Recruit_score\": 80},\n",
        "]\n",
        "\n",
        "# 正解ラベル\n",
        "labels = [0, 0, 1, 1, 0]\n",
        "\n",
        "# ルールを設定\n",
        "def predict_if(record):\n",
        "  # -----------採用と予測される条件を追記------------\n",
        "  if record[\"GPA\"] >= ?? and record[\"Internship\"] == ??:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "# 判定\n",
        "for i, (rec, true_label) in enumerate(zip(data, labels)):\n",
        "    pred = predict_if(rec)\n",
        "    print(f\"サンプル {i+1}: ルールベースによる出力 = {pred}, 正解 = {true_label}, {'✅' if pred == true_label else '❌'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ketlEwPLNor8"
      },
      "source": [
        "## 1-2.条件分岐を用いた予測\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtPK2EkVqDh5"
      },
      "outputs": [],
      "source": [
        "y_true = df_test[\"Label\"]\n",
        "y_pred = df_test.apply(predict_if, axis=1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(f\"IF文予測の精度: {acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnEB4w88Mr6G"
      },
      "source": [
        "# 2. ロジスティック回帰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z8d-IFoNYW-"
      },
      "source": [
        "## 2-1. 学習を行う前のロジスティック回帰（ランダムな重み）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EQu4FDdsTAN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from scipy.special import expit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# 可視化用関数\n",
        "def plot_network(weights, title):\n",
        "    G = nx.DiGraph()\n",
        "    input_nodes = feature_names\n",
        "    hidden_node = \"H1\"\n",
        "    output_node = \"HiringProb\"\n",
        "\n",
        "    for node in input_nodes:\n",
        "        G.add_node(node)\n",
        "    G.add_node(hidden_node)\n",
        "    G.add_node(output_node)\n",
        "\n",
        "    for i, node in enumerate(input_nodes):\n",
        "        G.add_edge(node, hidden_node, weight=weights[i])\n",
        "    G.add_edge(hidden_node, output_node, weight=1.0)\n",
        "\n",
        "    pos = {\n",
        "        \"GPA\": (-2, 3),\n",
        "        \"Programming\": (-2, 2),\n",
        "        \"Internship\": (-2, 1),\n",
        "        \"Recruit_score\": (-2, 0),\n",
        "        \"H1\": (0, 1.5),\n",
        "        \"HiringProb\": (2, 1.5)\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    nx.draw_networkx_nodes(G, pos, node_color='skyblue', node_size=2500)\n",
        "    nx.draw_networkx_labels(G, pos, font_size=10)\n",
        "\n",
        "    edges = G.edges(data=True)\n",
        "    nx.draw_networkx_edges(G, pos, edgelist=edges, arrowstyle='-|>', arrowsize=20)\n",
        "\n",
        "    # 重みラベル（出力層の重みは非表示）\n",
        "    edge_labels = {\n",
        "        (u, v): f\"{d['weight']:.2f}\"\n",
        "        for u, v, d in edges\n",
        "        if not (u == hidden_node and v == output_node)\n",
        "    }\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=9)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 特徴量名\n",
        "feature_names = [\"GPA\", \"Programming\", \"Internship\", \"Recruit_score\"]\n",
        "\n",
        "# --- データ準備 ---\n",
        "X_train = df_train[feature_names].values\n",
        "y_train = df_train[\"Label\"].values\n",
        "X_test = df_test[feature_names].values\n",
        "y_test = df_test[\"Label\"].values\n",
        "\n",
        "# スケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# 初期重み（ランダムに設定）\n",
        "np.random.seed(42)\n",
        "w_init = np.random.uniform(0, 1, size=X_train_scaled.shape[1])\n",
        "b_init = 0.0\n",
        "\n",
        "# 学習前の可視化\n",
        "plot_network(w_init, \"ロジスティック回帰（ランダムな重み）\")\n",
        "\n",
        "# === 学習前の精度を評価 ===\n",
        "z_init = np.dot(X_test_scaled, w_init) + b_init\n",
        "y_pred_init = (expit(z_init) >= 0.5).astype(int)\n",
        "acc_init = accuracy_score(y_test, y_pred_init)\n",
        "print(f\"予測精度: {acc_init:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEj7VlGgNc-1"
      },
      "source": [
        "## 2-2. ロジスティック回帰の学習と精度の向上"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUtIsaq1PVVf"
      },
      "outputs": [],
      "source": [
        "# --- 学習 ---\n",
        "w = w_init.copy()\n",
        "b = b_init\n",
        "lr = 0.1\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X_train_scaled, w) + b\n",
        "    y_pred = expit(z)\n",
        "    error = y_pred - y_train\n",
        "    dw = np.dot(X_train_scaled.T, error) / len(X_train_scaled)\n",
        "    db = np.mean(error)\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "# 学習後の可視化\n",
        "plot_network(w, \"ロジスティック回帰（学習後）\")\n",
        "\n",
        "# 学習後の精度\n",
        "z_test = np.dot(X_test_scaled, w) + b\n",
        "y_test_pred = (expit(z_test) >= 0.5).astype(int)\n",
        "acc_test = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"[学習後] 予測精度: {acc_test:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UL-NzQ1NxnG"
      },
      "source": [
        "# 3. ディープラーニング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_OALn6WRRMn"
      },
      "source": [
        "## 3-1. ディープラーニングの学習と予測\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7jbN4xuxEQi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.keras.utils import set_random_seed\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "set_random_seed(SEED)\n",
        "\n",
        "# 特徴量のスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Deep learningのモデルを設定\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=4, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(4, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # patience長め\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=16,  # 小さなbatch_sizeで更新頻度UP\n",
        "                   validation_split=0.2, callbacks=[early_stop], verbose=0)\n",
        "\n",
        "# テストデータで予測\n",
        "y_pred_nn = model.predict(X_test_scaled, verbose=0).flatten()\n",
        "y_pred_nn_class = (y_pred_nn > 0.5).astype(int)\n",
        "acc_nn = accuracy_score(y_test, y_pred_nn_class)\n",
        "\n",
        "# 結果表示\n",
        "improved_result = pd.DataFrame({\n",
        "    \"モデル\": [\"ディープラーニング\"],\n",
        "    \"正解率(Accuracy)\": [acc_nn]\n",
        "})\n",
        "print(\"ディープラーニングの精度：\", acc_nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5E3a9gZRUB1"
      },
      "source": [
        "## 3-2. ディープラーニングの重みの可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO-OVz0cxuU4"
      },
      "outputs": [],
      "source": [
        "# 最初のDense層（入力→隠れ1）の重みとバイアスを取得\n",
        "# 各層の重みとバイアスを取得\n",
        "W1, b1 = model.layers[0].get_weights()  # 入力 → 中間層1\n",
        "W2, b2 = model.layers[1].get_weights()  # 中間層1 → 中間層2\n",
        "W3, b3 = model.layers[2].get_weights()  # 中間層2 → 出力\n",
        "\n",
        "print(\"入力層→1層目間の重み：\\n\", W1)\n",
        "print(\"\\n1層目→2層目間の重み：\\n\", W2)\n",
        "print(\"\\n2層目→出力層の重み：\\n\", W3)\n",
        "\n",
        "\n",
        "# ノード定義\n",
        "input_nodes = [\"GPA\", \"Programming\", \"Internship\", \"Recruit_score\"]\n",
        "hidden1_nodes = [f\"H1_{i+1}\" for i in range(W1.shape[1])]\n",
        "hidden2_nodes = [f\"H2_{i+1}\" for i in range(W2.shape[1])]\n",
        "output_node = \"HiringProb\"\n",
        "\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# ノード追加\n",
        "for node in input_nodes + hidden1_nodes + hidden2_nodes + [output_node]:\n",
        "    G.add_node(node)\n",
        "\n",
        "# エッジ追加：入力層 → 隠れ層1\n",
        "for i, in_node in enumerate(input_nodes):\n",
        "    for j, h1_node in enumerate(hidden1_nodes):\n",
        "        G.add_edge(in_node, h1_node, weight=W1[i, j])\n",
        "\n",
        "# エッジ追加：隠れ層1 → 隠れ層2\n",
        "for i, h1_node in enumerate(hidden1_nodes):\n",
        "    for j, h2_node in enumerate(hidden2_nodes):\n",
        "        G.add_edge(h1_node, h2_node, weight=W2[i, j])\n",
        "\n",
        "# エッジ追加：隠れ層2 → 出力層\n",
        "for i, h2_node in enumerate(hidden2_nodes):\n",
        "    G.add_edge(h2_node, output_node, weight=W3[i, 0])\n",
        "\n",
        "# ノード配置\n",
        "pos = {}\n",
        "for i, node in enumerate(input_nodes):\n",
        "    pos[node] = (-3, len(input_nodes) - i)\n",
        "for i, node in enumerate(hidden1_nodes):\n",
        "    pos[node] = (-1, len(hidden1_nodes) / 2 - i)\n",
        "for i, node in enumerate(hidden2_nodes):\n",
        "    pos[node] = (1, len(hidden2_nodes) / 2 - i)\n",
        "pos[output_node] = (3, 0)\n",
        "\n",
        "# 描画\n",
        "plt.figure(figsize=(16, 10))\n",
        "nx.draw_networkx_nodes(G, pos, node_color='skyblue', node_size=1800)\n",
        "nx.draw_networkx_labels(G, pos, font_size=10)\n",
        "\n",
        "edges = G.edges(data=True)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=edges, arrowstyle='-|>', arrowsize=15)\n",
        "\n",
        "# 重みラベル（小さな値は省略）\n",
        "edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in edges if abs(d['weight']) > 0.1}\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
        "\n",
        "plt.title(\"学習済みニューラルネットの重み\", fontsize=14)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "iniad2025",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
